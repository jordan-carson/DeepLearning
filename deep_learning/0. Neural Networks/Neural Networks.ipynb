{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy\n",
    "\n",
    "The logarithm of any number between 0-1 is a negative number. So we take the negative of the sum of the logarithm.\n",
    "\n",
    "\n",
    "$$ \\log_b(xy) = \\log_bx + \\log_by $$\n",
    "\n",
    "A good model gives us a high probability and the negative of the logarithm of a large number is a small number and vice versa. \n",
    "\n",
    "We take the negative of the logarithm of the probability. Points that are correctly classified will have smaller errors than misclassified points.\n",
    "\n",
    "**Cross-Entropy**\n",
    "\n",
    "If I have a bunch of events and a bunch of probabilities, how likely is it that those events happen based on the probabilities?\n",
    "\n",
    "If its very likely, then we have a small cross-entropy, while if its unlikely, then we have a large cross entropy. \n",
    "\n",
    "$$ Cross-Entropy =  - \\sum y_{i}\\ln p_{i} + (1-y_{i}) \\ln(1-p_{i})$$\n",
    "\n",
    "**Multi-Class Cross Entropy**\n",
    "\n",
    "$$ - \\sum_{i=1}^n \\sum_{j=1}^m y_{ij}\\ln(p_{ij}) $$\n",
    "\n",
    "Cross-entropy is inversely proportional to the total probability of an outcome.\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "- Take your data\n",
    "- Pick a random model\n",
    "- Calculate the error\n",
    "- Minimize the error, and obtain a better model\n",
    "- Enjoy!\n",
    "\n",
    "\n",
    "**Error Function**\n",
    "\n",
    "$$ Error-Function =  - \\frac{1}{m} \\sum_{i=1}^m (1-y_{i})(\\ln(1 - \\hat{y_i})) + y_{i}\\ln \\hat{(y_i)} $$\n",
    "\n",
    "Since y_hat is given by the sigmid of the linear function wx + b, then the total formula for the error function is in terms of W, B, which are the weights of the model.\n",
    "\n",
    " $$ E(W, b) = - \\frac{1}{m} \\sum_{i=1}^m (1-y_{i})(\\ln(1 - \\sigma ( Wx^{(i)} + b) ) + y_{i}\\ln ( \\sigma ( Wx^{(i)} + b)) $$\n",
    "\n",
    "Our goal is to minimize the error function above, so we start with random weights, which will give us the predictions $ \\sigma (Wx^{(i)} + b) $. As we saw, that also gives us a error function given by the formula above. \n",
    "\n",
    "Remember that the summands are also error functions for each point. So each point will give us a larger function if its mis-classified and a smaller one if its correctly classified. \n",
    "\n",
    "And the way we will minimize this function is to use **gradient decent**.\n",
    "\n",
    "**Every error function must be continuous, and differentiable. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent \n",
    "\n",
    "Our error function is a function of the weights and can be graphed on a plane with w1, w2, and Error the height. \n",
    "\n",
    "The inputs of the functions are W1 and W2 and the error function is given by E. Then the gradient of E is given by the vector sum of the partial derivatives of E with respect to W1 an W2. This gradient actually tells us the direction we want to move if we want to increase the error function the most. Thus, if we take the negative of the gradient, this will tell us how to decrease the error funtion the most.\n",
    "\n",
    "\n",
    "We keep doing it until we are satisfied with our result.\n",
    "\n",
    "We start with our initial prediction. \n",
    "\n",
    "$$ \\hat{y} = \\sigma (Wx + b) $$\n",
    "\n",
    "\n",
    "the prediction looks like $$ \\hat{y} = \\sigma (w_{i}x_{i} +...+w_{n}x_{n} + b) $$\n",
    "\n",
    "Now the error function is given by the error function we saw before but what matters here is the gradient of the error function. Which is shown below:\n",
    "\n",
    "$$ \\nabla E = ( \\frac{\\partial E}{\\partial w_{i}}, ..., \\frac{\\partial E}{\\partial w_{n}}, \\frac{\\partial E}{\\partial b} )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of the error function is precisely the vector formed by the partial derivative of the error function with respect to the weights and the bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Rate**\n",
    "We take a step in the direction of the negative of the gradient. We do not want to take any drastic changes so we take a small learning rate alpha for example, 0.1, and we multiply the gradient by that number. \n",
    "\n",
    "$ \\alpha = 0.1 $\n",
    "\n",
    "Now the weight Wi wil now become Wi prime. Given by Wi minus alpha times the partial derivative of the error, with respect to Wi.  \n",
    "\n",
    "And the bias will now become b prime given by b minus alpha times the partial derivative of the error with respect to b. \n",
    "$$ w_{i}^{\\prime} \\leftarrow w_{i} - \\alpha \\frac{\\partial E}{\\partial w_{i}} $$\n",
    "\n",
    "$$ b^{\\prime} \\leftarrow b - \\alpha \\frac{\\partial E}{\\partial b} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can conclude that the prediciton we have now with weights $W^\\prime$ and $b^\\prime$, is better than the one we had before with weights W and b. \n",
    "\n",
    "1. Closer the label to the prediction, smaller the gradient.\n",
    "2. Farther the label from the prediction, larger the gradient.\n",
    "\n",
    "Great job! If a point is well classified, we will get a small gradient. And if it's poorly classified, the gradient will be quite large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Descent vs Perceptron**\n",
    "\n",
    "In the gradient descent algo, we take the weights and change them from $W_i \\leftarrow W_i + \\alpha (y - \\hat{y})x_i$ \n",
    "\n",
    "In the perceptron algo, not every point changes weights, only the misclassified ones. Here if X is misclassified, we'll change the weights by adding $X_i$ to $W_i$ if the point label is positive, and subtracting if its negative. \n",
    "\n",
    "Now the question is, are these two things the same?\n",
    "\n",
    "Remember in the perceptron algorithm, the labels are 1 and 0. And the predictions $ \\hat{y}$ are also 1 and 0. So, if the point is correct, classified, then $y - \\hat{y} = 0$ because $y = \\hat{y}$, \n",
    "\n",
    "Now if the point is labelled 'blue' then $ y = 1$ and if its misclassified, then the prediction must be $\\hat{y} = 0$ so  $\\hat{y} - y = -1 $\n",
    "\n",
    "The difference in gradient descent is that $\\hat{y}$ can take any number between zero and one. Whereas, in the perceptron algorithm $\\hat{y}$ can take only values 0 or 1. \n",
    "\n",
    "In both algorithms, if a point is misclassified tells a line to come closer because eventually, it wants the line to surpass it so it can be in the correct side. If the point is correctly classified, well the perceptron algorithm says do absolutely nothing. In the gradient descent algorithm, you are changing the weights, the point is telling the line to go farther away. This is exactly what Gradient Descent does, the misclassified points asks the line to come closer and the correctly classified points asks the line to go father away. The line listens to all the points and takes steps in such a way that it eventually arrives to a pretty good solution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "When training a neural network, we choose a method called backpropagation. In a nutshell, it consists of\n",
    "\n",
    "    - Doing a feedforward operation.\n",
    "    - Comparing the output of the model with the desired output. \n",
    "    - Calculating the error.\n",
    "    - Running the feedforward operation backwards (backpropagation) to spread the error to each of the weights.\n",
    "    - Use this to update the weights, and get a better model.\n",
    "    - Continue this until we have a model that is good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks Example\n",
    "### Implementing the basic functions\n",
    "Here is your turn to shine. Implement the following formulas, as explained in the text.\n",
    "- Sigmoid activation function\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + b)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i + \\alpha (y - \\hat{y}) x_i$$\n",
    "\n",
    "$$ b \\longrightarrow b + \\alpha (y - \\hat{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement the following functions\n",
    "import numpy as np\n",
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Output (prediction) formula\n",
    "def output_formula(features, weights, bias):\n",
    "    return sigmoid(np.dot(features, weights) + bias)\n",
    "    \n",
    "# Error (log-loss) formula\n",
    "def error_formula(y, output):\n",
    "    return -y*np.log(output)-(1-y)*np.log(1-output)\n",
    "\n",
    "# Gradient descent step\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    output = output_formula(x, weights, bias)\n",
    "    d_error = y - output\n",
    "    weights += learnrate * d_error * x\n",
    "    bias += learnrate * d_error\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
