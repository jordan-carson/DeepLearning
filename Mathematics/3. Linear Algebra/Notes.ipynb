{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear Algebra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Properties of Matrix and Vectors\n",
    "\n",
    "**Matrix** is a rectangular arrangement of numbers into rows and columns. Each number in a matrix is referred to as a matrix element or entry. \n",
    "\n",
    "\n",
    "### Scalar Multiplication\n",
    "\n",
    "The term **scalar multiplication** refers to the product of a real number and a matrix. In scalar multiplication, each entry in the matrix is multiplied by the given scalar. \n",
    "\n",
    "For example, given that $\\mathbf{A} = \\left[ \\begin{matrix} 10 & 6\\\\ 4 & 3 \\end{matrix} \\right]$\n",
    "\n",
    "Lets find $2 \\mathbf{A} = \\left[ \\begin{matrix} 20 & 12\\\\ 8 & 6 \\end{matrix} \\right]$ \n",
    "\n",
    "**Solving matrix equation**\n",
    "\n",
    "$\\mathbf{3A} = \\left[ \\begin{matrix} 3 & 24\\\\ 18 & 0 \\end{matrix} \\right]$\n",
    "\n",
    "Divide everything by 1/3, gives us\n",
    "\n",
    "$\\mathbf{A} = \\left[ \\begin{matrix} 1 & 8\\\\ 6 & 0 \\end{matrix} \\right]$\n",
    "\n",
    "\n",
    "### Linear Transformation\n",
    "In two dimensions, a two-dimension linear transformation is a special kind of function which takes in a two-dimensional vector and outputs another two-dimensional vector. We can think of smooshing something around, \n",
    "\n",
    "But must follow the geometric rule: The _origin must remain fixed_, and _all lines must remain lines_. \n",
    "\n",
    "#### Representing two dimension linear transforms with matices\n",
    "\n",
    "In general, each vector $\\begin{$\n",
    "\n",
    "A really nice way to describe all this is to represent a given linear transformation with the matrix below:\n",
    "\n",
    "\n",
    "\n",
    "$\\mathbf{A} = \\left[ \\begin{matrix} a & b\\\\ c & d \\end{matrix} \\right]$\n",
    "\n",
    "In this matrix, the first column tells us where \n",
    "\n",
    "### Transpose\n",
    "\n",
    "### Conjugate \n",
    "\n",
    "### Rank\n",
    "\n",
    "Count the number of pivot points, try to find rows to do row addition or subtraction to cancel some out, to make them zeros, note the rank cannot be greater than the number of rows or columns. \n",
    "\n",
    "A pivot point needs to have a zero to the left and below of it. \n",
    "\n",
    "### Determinant\n",
    "\n",
    "of a 2x2 matrix.\n",
    "\n",
    "Multiply the diagnols and subtract. \n",
    "\n",
    "of a 3x3 matrix.\n",
    "\n",
    "$$ \\mathbf{A} = \\left[ \\begin{matrix}\n",
    "    a_{11} & a_{12} & a_{13} \\\\\n",
    "    a_{21} & a_{22} & a_{23} \\\\\n",
    "    a_{31} & a_{32} & a_{33} \n",
    "   \\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    "Find the $\\text{det}(\\mathbf{A}) = \\left| \\mathbf{A} \\right|$\n",
    "\n",
    "Formula is\n",
    "$$ a_{11}\\left[ \\begin{matrix} \n",
    "        a_{22} & a_{23} \\\\ \n",
    "        a_{32} & a_{33} \n",
    "        \\end{matrix}\n",
    "        \\right]\n",
    "- a_{12} \\left[ \\begin{matrix} \n",
    "        a_{21} & a_{23} \\\\ \n",
    "        a_{31} & a_{33} \n",
    "        \\end{matrix}\n",
    "        \\right]\n",
    "+ a_{13} \\left[ \\begin{matrix} \n",
    "        a_{21} & a_{22} \\\\ \n",
    "        a_{31} & a_{32} \n",
    "        \\end{matrix}\n",
    "        \\right]\n",
    "$$\n",
    "\n",
    "#### Example:\n",
    "\n",
    "$$ \\mathbf{A} = \\left[ \\begin{matrix}\n",
    "    1 & 6 & 4 \\\\\n",
    "    2 & 7 & 3 \\\\\n",
    "    8 & 9 & 5 \n",
    "   \\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    " $$ 1\\left[ \\begin{matrix} \n",
    "        7 & 3 \\\\ \n",
    "        9 & 5 \n",
    "        \\end{matrix}\n",
    "        \\right]\n",
    "- 6 \\left[ \\begin{matrix} \n",
    "        2 & 3 \\\\ \n",
    "        8 & 5 \n",
    "        \\end{matrix}\n",
    "        \\right]\n",
    "+ 4 \\left[ \\begin{matrix} \n",
    "        2 & 7 \\\\ \n",
    "       8 & 9 \n",
    "        \\end{matrix}\n",
    "        \\right]\n",
    "$$         \n",
    "\n",
    "$$ = 1(7\\cdot5 - 3\\cdot9) - 6(2\\cdot5 - 3\\cdot8) + 4(2\\cdot9 - 8\\cdot7) $$\n",
    "\n",
    "$$ = 7 + 84 - 152 = -60$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Matrices\n",
    "\n",
    "### Square Matrix\n",
    "\n",
    "### Identity Matrix\n",
    "\n",
    "### Triangular Matrix\n",
    "\n",
    "### Idea about Spare and Dense Matrix\n",
    "\n",
    "### Unit Vectors\n",
    "\n",
    "### Symmetric Matrix\n",
    "\n",
    "### Hermitian \n",
    "\n",
    "### Skew-Hermitian \n",
    "\n",
    "### Unitary Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Facorization concept/LU Decomposition\n",
    "\n",
    "### Gaussian/Gauss-Jordan Elimination\n",
    "\n",
    "### Solving Ax=b Linear system of equation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Space\n",
    "\n",
    "### Basis\n",
    "\n",
    "### Span \n",
    "\n",
    "### Orthogonality\n",
    "\n",
    "### Orthonormality\n",
    "\n",
    "### Linear Least Square\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues\n",
    "\n",
    "### Eigenvectors\n",
    "\n",
    "### Diagonalization\n",
    "\n",
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues / Eigenvectors\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "For a particular matrix, vectors whose direction remains unchanged even after applying a linear transformation with the matrix are called **Eigenvectors**, for that particular matrix. The scaled up amount usually denoted as $\\lambda$ is called the **Eigenvalue**. \n",
    "\n",
    "#### Example: Multiplying a 2-dimension vector with a 2*2 matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([[1,2],[0,3]]) * np.array([1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$T: \\mathbf{R}^n \\rightarrow \\mathbf{R}$$\n",
    "\n",
    "The transformation of $x$ is equal to $A * x$, or\n",
    "\n",
    "$$T(\\vec{x}) = A$$\n",
    "\n",
    "Find the vectors that only get scaled up or down by the transformation. \n",
    "\n",
    "So we are interested in the vectors where I take the Transformation of some special vector $v$. \n",
    "\n",
    "$$T(\\vec{v}) = A\\vec{v}$$\n",
    "\n",
    "And we say it only gets scaled up by some factor, $\\lambda$ times $\\vec{v}$. \n",
    "\n",
    "$$T(\\vec{v}) = A\\vec{v} = \\lambda \\vec{v}$$\n",
    "\n",
    "This makes for interesting basis vectors, you know, the transformation matrix in the alternate basis, this is one of the basis vectors. \n",
    "\n",
    "And we call vectors that satisfy this condition **eigenvectors**. And we call their scaling factors the **eigenvalues** associated with this transformation and that $\\lambda$ eigenvector. \n",
    "\n",
    "$\\lambda$ = eigenvector, while $\\vec{v}$ = eigenvalue. \n",
    "\n",
    "So in general, we are looking for solutions to the equation \n",
    "\n",
    "$$A\\vec{v} = \\lambda \\vec{v} $$\n",
    "\n",
    "Initally we may think that $\\vec{v} = \\vec{0}$, which is a solution, although it's not normally considered to be an eigenvector just because its not a useful basis vector. It doesn't add anything to a basis, and doesn't add really the amount of vectors that you can span when you throw the basis vector in. And also, its not clear what is your eigenvalue that's associated with it, because if $\\vec{v}$ is equal to $0$ then any eigenvalue will work for it. \n",
    "\n",
    "Normally when we're looking for eigenvectors, we start with the assumption that we're looking for non-zero vectors. \n",
    "\n",
    "$$\\vec{v} \\neq \\vec{0} $$\n",
    "\n",
    "So we subtract $A\\vec{v}$ from both sides, we get\n",
    "\n",
    "$$\\vec{0} = \\lambda \\vec{v} - A \\vec{v} $$\n",
    "\n",
    "Now, we can rewrite $\\vec{v}$ as, vector v equals the identity matrix times vector v, as v is a member of $\\mathbf{R}_n$. The identity matrix $\\mathbf{I}_n$ is an $NxN$ matrix\n",
    "\n",
    "$$\\vec{v} = \\mathbf{I}_n \\vec{v}$$\n",
    "\n",
    "So we can rewrite the above equation as\n",
    "\n",
    "$$ \\lambda \\mathbf{I}_n \\vec{v} - A\\vec{v} = 0$$\n",
    "\n",
    "So we have one matrix times v minus another matrix times v, and as we remember from linear algebra matrix vector products have a distributive property. So this is equivalent to the matrix lambda times the identity matrix minus A times the vector v. \n",
    "\n",
    "$$\\left(\\lambda \\mathbf{I}_n - A \\right) \\vec{v} = \\vec{0} $$\n",
    "\n",
    "So everything inside the parentheses above is just some matrix, and the whole reason why I made this substitution is so I can write this as a matrix vector product instead of just a scalar vector product. That way we can essentially factor out the $v$ and write this whole equation as essentially, some matrix vector product is equal to 0. \n",
    "\n",
    "Now, if we assume that this is the case, where $\\vec{v} \\neq 0$, what does this mean?\n",
    "\n",
    "So we know that $v$ is a member of the null space of this matrix.\n",
    "\n",
    "$$\\vec{v} \\in N \\left( \\lambda \\mathbf{I}_n - A \\right) $$\n",
    "\n",
    "The null space of$ \\left( \\lambda \\mathbf{I}_n - A \\right)$, which we can call some matrix $\\mathbf{B}$ is all of the vectors x that are a member of $\\mathbf{R}_n$ such that $\\mathbf{B} \\times x = 0$\n",
    "\n",
    "$$ N(B) = \\left( \\vec{x} \\in \\mathbf{R}_n \\| \\mathbf{B} \\vec{x} = 0 \\right)$$\n",
    "\n",
    "Well $\\vec{v}$ must be one of these two, because $\\mathbf{B}$ times $\\vec{v}$ is equal to 0. \n",
    "\n",
    "We're assuming B solves this equation and that gets all the way to the assumption that B must solve this equation. And v is not equal to 0. So v is a member of the null space and this is a nontrivial member of the null space. We already said the 0 vector is always going to be a member "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
